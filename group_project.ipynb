{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "daily_returns = sc.textFile(\"s3n://msan-usf-gproject/daily_returns.csv\")\n",
    "header = daily_returns.first()\n",
    "\n",
    "rdd = daily_returns.filter(lambda x: x != header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10.0,\n",
       "  0.0,\n",
       "  0.370326220989,\n",
       "  -0.00631639920175,\n",
       "  0.222831085324,\n",
       "  -0.213030129671,\n",
       "  0.729276776314,\n",
       "  -0.335633248091,\n",
       "  0.113292053342,\n",
       "  1.62123823166,\n",
       "  -0.179403930902,\n",
       "  0.0,\n",
       "  -0.0721078515053,\n",
       "  0.249186635017,\n",
       "  0.0244014300406,\n",
       "  -0.127942487597,\n",
       "  0.0,\n",
       "  1.41274225712,\n",
       "  -0.0295753479004,\n",
       "  1.26524603367,\n",
       "  -0.0557470582426,\n",
       "  1.59225594997,\n",
       "  -0.285275280476,\n",
       "  -0.212887898088,\n",
       "  0.40418022871,\n",
       "  0.116902828217,\n",
       "  0.197589740157,\n",
       "  -0.197454556823,\n",
       "  -0.195023342967,\n",
       "  -0.0598861537874,\n",
       "  -0.0211989730597,\n",
       "  -0.0135547351092,\n",
       "  -0.236370578408,\n",
       "  -0.253357321024,\n",
       "  0.575561583042,\n",
       "  0.283947110176,\n",
       "  -0.00620764028281,\n",
       "  0.616350948811,\n",
       "  -0.0345781445503,\n",
       "  0.732652306557,\n",
       "  -0.00243225856684,\n",
       "  -0.0925076529384,\n",
       "  -0.0721848458052,\n",
       "  0.447295695543,\n",
       "  -0.194317787886,\n",
       "  0.264373421669,\n",
       "  0.01876296103,\n",
       "  0.0,\n",
       "  -0.145278140903,\n",
       "  -0.108546897769,\n",
       "  0.148189216852,\n",
       "  -0.226942017674,\n",
       "  0.262863576412,\n",
       "  -0.252933114767,\n",
       "  -0.113264843822,\n",
       "  0.180559366941,\n",
       "  -0.0338116437197,\n",
       "  0.0429507419467,\n",
       "  -0.0680313110352,\n",
       "  0.208402082324,\n",
       "  -0.0827429741621,\n",
       "  1.06105899811,\n",
       "  1.12080144882,\n",
       "  -0.228200241923,\n",
       "  -0.119987480342,\n",
       "  -0.131929144263,\n",
       "  -0.145984902978,\n",
       "  -0.155988737941,\n",
       "  0.0,\n",
       "  0.0376801341772,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  -2.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  -2.0,\n",
       "  -0.273957371712,\n",
       "  0.0,\n",
       "  -2.0,\n",
       "  -2.0,\n",
       "  0.0,\n",
       "  0.00165155075956,\n",
       "  -2.0,\n",
       "  0.0,\n",
       "  -2.0,\n",
       "  0.0,\n",
       "  0.652980566025,\n",
       "  0.0,\n",
       "  -0.142452836037,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.42746901512,\n",
       "  0.0,\n",
       "  -2.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.937880218029,\n",
       "  0.775208115578,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  -0.414775848389,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  -2.0,\n",
       "  0.0,\n",
       "  -0.0117534492165)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def toDouble(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except ValueError:\n",
    "        return 0.0\n",
    "    \n",
    "rddSplit = rdd.map(lambda x: x.split(','))\n",
    "rddDoubles = rddSplit.map(lambda x: tuple([toDouble(val) for val in x]))\n",
    "rddDoubles.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+\n",
      "|  id|timestamp|\n",
      "+----+---------+\n",
      "|10.0|      0.0|\n",
      "|11.0|      0.0|\n",
      "|12.0|      0.0|\n",
      "|25.0|      0.0|\n",
      "|26.0|      0.0|\n",
      "|27.0|      0.0|\n",
      "|31.0|      0.0|\n",
      "|38.0|      0.0|\n",
      "|39.0|      0.0|\n",
      "|40.0|      0.0|\n",
      "|41.0|      0.0|\n",
      "|43.0|      0.0|\n",
      "|44.0|      0.0|\n",
      "|49.0|      0.0|\n",
      "|54.0|      0.0|\n",
      "|59.0|      0.0|\n",
      "|60.0|      0.0|\n",
      "|62.0|      0.0|\n",
      "|63.0|      0.0|\n",
      "|68.0|      0.0|\n",
      "+----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = sqlContext.createDataFrame(rddDoubles,  header.split(','))\n",
    "df.select('id', 'timestamp').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = df.where('timestamp < 906')\n",
    "df_test = df.where('timestamp >= 906')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "va_train = VectorAssembler(outputCol=\"features\", inputCols=df_train.columns[2:-1])\n",
    "va_test = VectorAssembler(outputCol=\"features\", inputCols=df_test.columns[2:-1])\n",
    "train = va_train.transform(df_train).select(\"features\", \"y\").cache()\n",
    "test = va_test.transform(df_test).select(\"features\", \"y\").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = train.withColumnRenamed(existing='y', new='label')\n",
    "test = test.withColumnRenamed(existing='y', new='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "rf = RandomForestRegressor(numTrees=100, maxDepth=5)\n",
    "rfmodel = rf.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfpredcitions = rfmodel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = rfpredcitions.select(\"prediction\").rdd.map(lambda r: r[0]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = rfpredcitions.select(\"label\").rdd.map(lambda r: r[0]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0254168611149\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "pred = np.array(pred)\n",
    "labels = np.array(labels)\n",
    "\n",
    "def rvalue(pred, y):\n",
    "    mu = np.mean(y)\n",
    "    rsquare = 1 - sum( (y - pred)**2 ) / sum ( (y - mu )**2)\n",
    "    r = np.sign(rsquare) * np.sqrt( abs(rsquare) )\n",
    "    \n",
    "    return r\n",
    "\n",
    "print rvalue(pred, labels)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
